{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43904d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8adfbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>연도</th>\n",
       "      <th>시군구</th>\n",
       "      <th>법정동코드</th>\n",
       "      <th>사고내용</th>\n",
       "      <th>사망자수</th>\n",
       "      <th>중상자수</th>\n",
       "      <th>경상자수</th>\n",
       "      <th>부상신고자수</th>\n",
       "      <th>사고유형</th>\n",
       "      <th>도로형태</th>\n",
       "      <th>피해자 상해정도</th>\n",
       "      <th>피해가중점수</th>\n",
       "      <th>사고도로조합</th>\n",
       "      <th>시군구_평균사고</th>\n",
       "      <th>사고유형가중치</th>\n",
       "      <th>도로형태가중치</th>\n",
       "      <th>최종위험점수</th>\n",
       "      <th>위험도</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>서울특별시 종로구 창성동</td>\n",
       "      <td>1111010500</td>\n",
       "      <td>중상사고</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>차대사람 - 차도통행중</td>\n",
       "      <td>교차로 - 교차로부근</td>\n",
       "      <td>중상</td>\n",
       "      <td>0.10</td>\n",
       "      <td>차대사람 - 차도통행중_교차로 - 교차로부근</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.131882</td>\n",
       "      <td>0.111938</td>\n",
       "      <td>0.221910</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>서울특별시 종로구 창성동</td>\n",
       "      <td>1111010500</td>\n",
       "      <td>중상사고</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>차대사람 - 차도통행중</td>\n",
       "      <td>교차로 - 교차로안</td>\n",
       "      <td>중상</td>\n",
       "      <td>0.10</td>\n",
       "      <td>차대사람 - 차도통행중_교차로 - 교차로안</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.131882</td>\n",
       "      <td>0.117951</td>\n",
       "      <td>0.224917</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>서울특별시 종로구 통인동</td>\n",
       "      <td>1111010800</td>\n",
       "      <td>경상사고</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>차대사람 - 기타</td>\n",
       "      <td>단일로 - 기타</td>\n",
       "      <td>경상</td>\n",
       "      <td>0.01</td>\n",
       "      <td>차대사람 - 기타_단일로 - 기타</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.092425</td>\n",
       "      <td>0.121204</td>\n",
       "      <td>0.116814</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>서울특별시 종로구 누상동</td>\n",
       "      <td>1111010900</td>\n",
       "      <td>경상사고</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>차대사람 - 차도통행중</td>\n",
       "      <td>교차로 - 교차로안</td>\n",
       "      <td>경상</td>\n",
       "      <td>0.01</td>\n",
       "      <td>차대사람 - 차도통행중_교차로 - 교차로안</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.131882</td>\n",
       "      <td>0.117951</td>\n",
       "      <td>0.134917</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>서울특별시 종로구 누상동</td>\n",
       "      <td>1111010900</td>\n",
       "      <td>경상사고</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>차대사람 - 기타</td>\n",
       "      <td>단일로 - 기타</td>\n",
       "      <td>경상</td>\n",
       "      <td>0.01</td>\n",
       "      <td>차대사람 - 기타_단일로 - 기타</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.092425</td>\n",
       "      <td>0.121204</td>\n",
       "      <td>0.116814</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_type = pd.read_csv('../../preprocessed_data/시도_시군구별_보행자_사고_사고유형_전처리ver.csv')\n",
    "\n",
    "# 피해 가중 점수 계산\n",
    "df_risk = df_type.copy()\n",
    "df_risk['피해가중점수'] = (\n",
    "    df_risk['사망자수'] * 1 +\n",
    "    df_risk['중상자수'] * 0.1 +\n",
    "    df_risk['경상자수'] * 0.01 +\n",
    "    df_risk['부상신고자수'] * 0.001\n",
    ")\n",
    "\n",
    "avg_by_area = df_risk.groupby('시군구')['피해가중점수'].mean().to_dict()        # 시군구별 평균 사고건수 feature 생성\n",
    "type_weight = df_risk.groupby('사고유형')['피해가중점수'].mean()                 # 사고형태_가중치 = 사고유형별_누적_피해점수 / 전체_평균_피해점수\n",
    "road_weight = df_risk.groupby('도로형태')['피해가중점수'].mean()                 # 도로형태_가중치 = 도로형태별_누적_피해점수 / 전체_평균_피해점수\n",
    "\n",
    "df_risk['사고도로조합'] = df_risk['사고유형'] + '_' + df_risk['도로형태']                                        # 사고유형 + 도로형태 조합 변수 생성\n",
    "df_risk['시군구_평균사고'] = df_risk['시군구'].map(avg_by_area)\n",
    "df_risk['사고유형가중치'] = df_risk['사고유형'].map(type_weight)\n",
    "df_risk['도로형태가중치'] = df_risk['도로형태'].map(road_weight)\n",
    "df_risk['최종위험점수'] = df_risk['피해가중점수'] + 0.5 * (df_risk['사고유형가중치'] + df_risk['도로형태가중치'])       # 최종 위험 점수 계산 (기본 피해 점수 + 유형/도로 가중치 평균)\n",
    "\n",
    "df_risk['위험도'] = pd.qcut(df_risk['최종위험점수'], q=5, labels=[1, 2, 3, 4, 5])                             # 위험도 5등급 (1=매우 안전 ~ 5=매우 위험)\n",
    "df_risk['위험도'] = df_risk['위험도'].astype(str)\n",
    "\n",
    "HTML(df_risk.head(5).to_html(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2845bc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.4.0: Fri Apr 11 18:33:39 PDT 2025; root:xnu-11417.101.15~117/RELEASE_ARM64_T6020\n",
      "CPU Count:          12\n",
      "Memory Avail:       2.74 GB / 16.00 GB (17.1%)\n",
      "Disk Space Avail:   11.84 GB / 460.43 GB (2.6%)\n",
      "===================================================\n",
      "Presets specified: ['high_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 225s of the 900s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-06-05 16:18:59,301\tINFO worker.py:1843 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"/Users/leehyunseung/Documents/GitHub/1_team_project/notebooks/03_modeling/HighRiskRank/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Beginning AutoGluon training ... Time limit = 223s\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m AutoGluon will save models to \"/Users/leehyunseung/Documents/GitHub/1_team_project/notebooks/03_modeling/HighRiskRank/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Train Data Rows:    36743\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Train Data Columns: 5\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Label Column:       위험도\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Problem Type:       multiclass\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Train Data Class Count: 5\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tAvailable Memory:                    2809.27 MB\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tTrain Data (Original)  Memory Usage: 15.54 MB (0.6% of available memory)\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t\tFitting TextSpecialFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t\t\tFitting BinnedFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t\tFitting TextNgramFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t\t\tFitting CountVectorizer for text features: ['시군구']\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t\t\tCountVectorizer fit with vocabulary size = 95\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t\t('float', [])        : 1 | ['시군구_평균사고']\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t\t('object', [])       : 3 | ['사고유형', '도로형태', '사고도로조합']\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t\t('object', ['text']) : 1 | ['시군구']\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t\t('category', [])                    :  3 | ['사고유형', '도로형태', '사고도로조합']\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t\t('category', ['text_as_category'])  :  1 | ['시군구']\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t\t('float', [])                       :  1 | ['시군구_평균사고']\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t\t('int', ['binned', 'text_special']) :  4 | ['시군구.char_count', '시군구.word_count', '시군구.digit_ratio', '시군구.symbol_ratio. ']\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t\t('int', ['text_ngram'])             : 67 | ['__nlp__.강릉시', '__nlp__.강원도', '__nlp__.강원특별자치도', '__nlp__.경기도', '__nlp__.경기도 고양시', ...]\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t1.9s = Fit runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t5 features in original data used to generate 76 features in processed data.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tTrain Data (Processed) Memory Usage: 5.29 MB (0.2% of available memory)\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Data preprocessing and feature engineering runtime = 1.93s ...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 147.11s of the 220.72s of remaining time.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.2431\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.96s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 145.08s of the 218.69s of remaining time.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.2398\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.99s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 144.03s of the 217.63s of remaining time.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.22%)\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:19:09,282 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 10.8146 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:19:19,317 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 10.8172 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.5773\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t20.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.57s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 122.02s of the 195.62s of remaining time.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.60%)\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:19:29,404 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 9.80325 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.5818\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t2.64s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.44s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 114.17s of the 187.78s of remaining time.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.68%)\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:19:39,505 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 9.79909 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.5795\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t4.28s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.33s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 108.29s of the 181.90s of remaining time.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tWarning: Reducing model 'n_estimators' from 300 -> 263 due to low memory. Expected memory usage reduced from 17.05% -> 15.0% of available memory...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.5166\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t2.35s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t1.15s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 103.95s of the 177.55s of remaining time.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tWarning: Reducing model 'n_estimators' from 300 -> 246 due to low memory. Expected memory usage reduced from 18.28% -> 15.0% of available memory...\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:19:49,557 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 9.26825 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.516\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t2.18s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t1.16s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 99.73s of the 173.34s of remaining time.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 14.90% memory usage per fold, 59.58%/80.00% total).\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=14.90%)\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:19:59,642 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 8.76744 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:20:09,646 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 8.77041 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:20:19,748 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 8.76472 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:20:29,788 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 8.7761 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[36m(_ray_fit pid=19454)\u001b[0m \tRan out of time, early stopping on iteration 204.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:20:39,851 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 8.77694 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[36m(_ray_fit pid=19507)\u001b[0m \tRan out of time, early stopping on iteration 201.\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:20:49,944 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 8.77547 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:20:59,952 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 8.7733 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:21:10,045 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 8.76986 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[36m(_ray_fit pid=19652)\u001b[0m \tRan out of time, early stopping on iteration 395.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.5892\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t81.48s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.26s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 16.26s of the 89.87s of remaining time.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tWarning: Reducing model 'n_estimators' from 300 -> 221 due to low memory. Expected memory usage reduced from 20.34% -> 15.0% of available memory...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.511\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t1.38s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t1.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 13.07s of the 86.68s of remaining time.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tWarning: Reducing model 'n_estimators' from 300 -> 212 due to low memory. Expected memory usage reduced from 21.17% -> 15.0% of available memory...\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:21:20,050 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 8.23721 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.5116\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t1.35s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t1.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 9.37s of the 82.98s of remaining time.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.89%)\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:21:30,099 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 7.75666 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.5848\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t6.76s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.84s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 220.72s of the 73.52s of remaining time.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 0.72, 'LightGBM_BAG_L1': 0.28}\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.5898\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.8s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 72.71s of the 72.66s of remaining time.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=4.13%)\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:21:40,127 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 7.74994 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:21:50,129 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 7.74919 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[36m(_ray_fit pid=19812)\u001b[0m No improvement since epoch 3: early stopping\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.593\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t25.15s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.35s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 45.10s of the 45.05s of remaining time.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=4.10%)\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:22:00,195 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 7.74468 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[36m(_ray_fit pid=19774)\u001b[0m No improvement since epoch 4: early stopping\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:22:10,265 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 7.74603 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:22:20,310 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 7.73404 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=19886)\u001b[0m [1000]\tvalid_set's multi_error: 0.3231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:22:30,331 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 7.7342 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[36m(_ray_fit pid=19815)\u001b[0m \tRan out of time, early stopping on iteration 1415. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=19815)\u001b[0m \t[1403]\tvalid_set's multi_error: 0.309819\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:22:40,440 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 7.73468 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[36m(_ray_fit pid=19888)\u001b[0m \tRan out of time, early stopping on iteration 1436. Best iteration is:\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=19888)\u001b[0m \t[1434]\tvalid_set's multi_error: 0.306838\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:22:50,495 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 7.73098 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.6951\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t38.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t91.46s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 220.72s of the -8.47s of remaining time.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L2': 1.0}\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.6951\t = Validation score   (accuracy)\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t1.06s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m AutoGluon training complete, total runtime = 232.29s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 48.5 rows/s (4593 batch size)\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.96s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.03s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.99s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:23:00,527 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 7.70777 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tStopping at the best epoch learned earlier - 18.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t10.79s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t1.16s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.51s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t2.35s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t1.15s\t = Validation runtime\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:23:10,624 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 6.76725 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t2.18s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t1.16s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t4.87s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t1.38s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t1.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t1.35s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t1.13s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t1.08s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 0.72, 'LightGBM_BAG_L1': 0.28}\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t0.8s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:23:20,721 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 5.72474 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:23:30,811 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 5.72069 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tStopping at the best epoch learned earlier - 18.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t13.21s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting 1 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:23:40,812 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 5.72037 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:23:50,898 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 5.71455 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:24:00,911 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 5.71654 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t34.36s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L2': 1.0}\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m \t1.06s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Updated best model to \"LightGBMXT_BAG_L2_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"LightGBMXT_BAG_L2_FULL\" for predict() and predict_proba().\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Refit complete, total runtime = 74.39s ... Best model: \"LightGBMXT_BAG_L2_FULL\"\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/leehyunseung/Documents/GitHub/1_team_project/notebooks/03_modeling/HighRiskRank/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[33m(raylet)\u001b[0m [2025-06-05 16:24:10,960 E 19328 29509675] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-06-05_16-18-57_964745_19122 is over 95% full, available space: 5.68461 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[36m(_dystack pid=19341)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                           model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0           CatBoost_BAG_L1_FULL       0.593730   0.589228    accuracy        0.019213            NaN   4.868982                 0.019213                     NaN           4.868982            1       True          8\n",
      "1       WeightedEnsemble_L2_FULL       0.591770   0.589827    accuracy        0.030861            NaN   6.185664                 0.003372                     NaN           0.802851            2       True         12\n",
      "2            XGBoost_BAG_L1_FULL       0.585674   0.584846    accuracy        0.059292            NaN   1.084078                 0.059292                     NaN           1.084078            1       True         11\n",
      "3         LightGBMXT_BAG_L1_FULL       0.580884   0.581798    accuracy        0.017030            NaN   1.161101                 0.017030                     NaN           1.161101            1       True          4\n",
      "4    NeuralNetFastAI_BAG_L2_FULL       0.580231   0.592956    accuracy        2.804306            NaN  38.951690                 0.070690                     NaN          13.212260            2       True         13\n",
      "5         LightGBMXT_BAG_L2_FULL       0.574570   0.695098    accuracy        3.356084            NaN  60.103241                 0.622469                     NaN          34.363811            2       True         14\n",
      "6       WeightedEnsemble_L3_FULL       0.574570   0.695098    accuracy        3.357016            NaN  61.165825                 0.000932                     NaN           1.062584            3       True         15\n",
      "7           LightGBM_BAG_L1_FULL       0.572175   0.579512    accuracy        0.008276            NaN   0.513831                 0.008276                     NaN           0.513831            1       True          5\n",
      "8    NeuralNetFastAI_BAG_L1_FULL       0.564772   0.577280    accuracy        0.050970            NaN  10.787577                 0.050970                     NaN          10.787577            1       True          3\n",
      "9   RandomForestEntr_BAG_L1_FULL       0.519704   0.515962    accuracy        0.489864       1.157352   2.183744                 0.489864                1.157352           2.183744            1       True          7\n",
      "10  RandomForestGini_BAG_L1_FULL       0.519486   0.516561    accuracy        0.625239       1.150730   2.353579                 0.625239                1.150730           2.353579            1       True          6\n",
      "11    ExtraTreesGini_BAG_L1_FULL       0.517744   0.511036    accuracy        0.470698       1.086495   1.382647                 0.470698                1.086495           1.382647            1       True          9\n",
      "12    ExtraTreesEntr_BAG_L1_FULL       0.515567   0.511608    accuracy        0.442883       1.128322   1.349031                 0.442883                1.128322           1.349031            1       True         10\n",
      "13    KNeighborsUnif_BAG_L1_FULL       0.239495   0.243121    accuracy        0.390236       0.962499   0.028146                 0.390236                0.962499           0.028146            1       True          1\n",
      "14    KNeighborsDist_BAG_L1_FULL       0.235794   0.239774    accuracy        0.159915       0.987776   0.026713                 0.159915                0.987776           0.026713            1       True          2\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t314s\t = DyStack   runtime |\t586s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 586s\n",
      "AutoGluon will save models to \"/Users/leehyunseung/Documents/GitHub/1_team_project/notebooks/03_modeling/HighRiskRank\"\n",
      "Train Data Rows:    41336\n",
      "Train Data Columns: 5\n",
      "Label Column:       위험도\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 5\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3230.97 MB\n",
      "\tTrain Data (Original)  Memory Usage: 22.79 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['시군구']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 104\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 1 | ['시군구_평균사고']\n",
      "\t\t('object', [])       : 3 | ['사고유형', '도로형태', '사고도로조합']\n",
      "\t\t('object', ['text']) : 1 | ['시군구']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :  3 | ['사고유형', '도로형태', '사고도로조합']\n",
      "\t\t('category', ['text_as_category'])  :  1 | ['시군구']\n",
      "\t\t('float', [])                       :  1 | ['시군구_평균사고']\n",
      "\t\t('int', ['binned', 'text_special']) :  4 | ['시군구.char_count', '시군구.word_count', '시군구.digit_ratio', '시군구.symbol_ratio. ']\n",
      "\t\t('int', ['text_ngram'])             : 73 | ['__nlp__.강릉시', '__nlp__.강원도', '__nlp__.강원특별자치도', '__nlp__.경기도', '__nlp__.경기도 고양시', ...]\n",
      "\t2.3s = Fit runtime\n",
      "\t5 features in original data used to generate 82 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 6.43 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.34s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 583.31s of the 583.30s of remaining time.\n",
      "\t0.243\t = Validation score   (accuracy)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.49s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 580.18s of the 580.17s of remaining time.\n",
      "\t0.2401\t = Validation score   (accuracy)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.42s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 578.61s of the 578.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.49%)\n",
      "\t0.5763\t = Validation score   (accuracy)\n",
      "\t26.07s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 549.72s of the 549.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.87%)\n",
      "\t0.5832\t = Validation score   (accuracy)\n",
      "\t3.35s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 543.60s of the 543.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.21%)\n",
      "\t0.5792\t = Validation score   (accuracy)\n",
      "\t3.29s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 538.62s of the 538.61s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 251 due to low memory. Expected memory usage reduced from 17.91% -> 15.0% of available memory...\n",
      "\t0.5193\t = Validation score   (accuracy)\n",
      "\t2.37s\t = Training   runtime\n",
      "\t1.57s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 532.38s of the 532.37s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 214 due to low memory. Expected memory usage reduced from 21.02% -> 15.0% of available memory...\n",
      "\t0.5179\t = Validation score   (accuracy)\n",
      "\t2.91s\t = Training   runtime\n",
      "\t1.29s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 526.42s of the 526.41s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 16.55% memory usage per fold, 66.22%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=16.55%)\n",
      "\t0.598\t = Validation score   (accuracy)\n",
      "\t210.52s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 314.05s of the 314.05s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 182 due to low memory. Expected memory usage reduced from 24.66% -> 15.0% of available memory...\n",
      "\t0.5143\t = Validation score   (accuracy)\n",
      "\t2.24s\t = Training   runtime\n",
      "\t1.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 308.93s of the 308.92s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 178 due to low memory. Expected memory usage reduced from 25.2% -> 15.0% of available memory...\n",
      "\t0.5133\t = Validation score   (accuracy)\n",
      "\t1.63s\t = Training   runtime\n",
      "\t1.04s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 303.65s of the 303.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.44%)\n",
      "\t0.5847\t = Validation score   (accuracy)\n",
      "\t7.0s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 293.58s of the 293.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.12%)\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=21006, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2169, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/ray/_private/worker.py\", line 2782, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/ray/_private/worker.py\", line 929, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=21006, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 290.35s of the 290.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=4.47%)\n",
      "\t0.5754\t = Validation score   (accuracy)\n",
      "\t3.63s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 285.17s of the 285.16s of remaining time.\n",
      "2025-06-05 16:29:12,567\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-06-05 16:29:12,570\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-06-05 16:29:12,572\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=21008, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "2025-06-05 16:29:12,574\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=21007, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "2025-06-05 16:29:12,574\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-06-05 16:29:12,575\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-06-05 16:29:12,576\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 14.22% memory usage per fold, 56.90%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=14.22%)\n",
      "\t0.5977\t = Validation score   (accuracy)\n",
      "\t80.71s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 202.83s of the 202.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.34%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r79_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=21277, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2169, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/ray/_private/worker.py\", line 2782, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/ray/_private/worker.py\", line 929, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=21277, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 197.96s of the 197.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=3.49%)\n",
      "2025-06-05 16:30:45,217\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=21274, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "2025-06-05 16:30:45,224\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=21278, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "2025-06-05 16:30:45,225\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=21271, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "2025-06-05 16:30:45,227\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=21275, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "2025-06-05 16:30:45,229\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=21272, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "2025-06-05 16:30:45,233\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-06-05 16:30:45,234\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=21273, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\t0.5804\t = Validation score   (accuracy)\n",
      "\t5.6s\t = Training   runtime\n",
      "\t1.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 189.11s of the 189.10s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=2.29%)\n",
      "\t0.5756\t = Validation score   (accuracy)\n",
      "\t85.72s\t = Training   runtime\n",
      "\t0.65s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 101.60s of the 101.59s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 13.78% memory usage per fold, 55.12%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=13.78%)\n",
      "\t0.592\t = Validation score   (accuracy)\n",
      "\t82.63s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 17.04s of the 17.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.95%)\n",
      "\t0.5823\t = Validation score   (accuracy)\n",
      "\t8.04s\t = Training   runtime\n",
      "\t2.81s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 6.23s of the 6.22s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.14%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r22_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=21799, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2169, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/ray/_private/worker.py\", line 2782, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/ray/_private/worker.py\", line 929, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=21799, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 3.18s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 1.0}\n",
      "\t0.598\t = Validation score   (accuracy)\n",
      "\t1.3s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 583.8s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 17808.5 rows/s (5167 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.49s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.04s\t = Training   runtime\n",
      "\t1.42s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "2025-06-05 16:34:00,087\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-06-05 16:34:00,088\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=21755, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "2025-06-05 16:34:00,088\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-06-05 16:34:00,089\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-06-05 16:34:00,091\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=21795, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "2025-06-05 16:34:00,092\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-06-05 16:34:00,093\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tStopping at the best epoch learned earlier - 18.\n",
      "\t10.95s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t0.98s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.49s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t2.37s\t = Training   runtime\n",
      "\t1.57s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t2.91s\t = Training   runtime\n",
      "\t1.29s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t19.52s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t2.24s\t = Training   runtime\n",
      "\t1.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.63s\t = Training   runtime\n",
      "\t1.04s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t1.44s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t1.41s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r177_BAG_L1_FULL ...\n",
      "\t6.78s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r131_BAG_L1_FULL ...\n",
      "\t1.61s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1_FULL ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t25.37s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r9_BAG_L1_FULL ...\n",
      "\t10.55s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_r96_BAG_L1_FULL ...\n",
      "\t3.19s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 1.0}\n",
      "\t1.3s\t = Training   runtime\n",
      "Updated best model to \"CatBoost_BAG_L1_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"CatBoost_BAG_L1_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 91.37s ... Best model: \"CatBoost_BAG_L1_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/leehyunseung/Documents/GitHub/1_team_project/notebooks/03_modeling/HighRiskRank\")\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/leehyunseung/Documents/GitHub/1_team_project/notebooks/03_modeling/HighRiskRank\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.595355587808418,\n",
       " 'balanced_accuracy': 0.5860691577804529,\n",
       " 'mcc': 0.49793465678837673}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = ['시군구', '사고유형', '도로형태', '시군구_평균사고', '사고도로조합']            # feature 선택\n",
    "target_col = '위험도'\n",
    "\n",
    "df_model = df_risk[feature_cols + [target_col]].dropna()\n",
    "\n",
    "train_data, test_data = train_test_split(df_risk[feature_cols + [target_col]], test_size=0.2, random_state=42, stratify=df_risk[target_col])\n",
    "\n",
    "# 모델 학습 (AutoGluon)\n",
    "predictor = TabularPredictor(label=target_col, path=\"HighRiskRank/\", problem_type='multiclass').fit(\n",
    "    train_data=train_data,\n",
    "    presets='high_quality',\n",
    "    num_cpus=10,\n",
    "    time_limit=900,\n",
    "    verbosity=2\n",
    ")\n",
    "\n",
    "# predictor.save()                    # 모델 저장\n",
    "predictor.evaluate(test_data)       # 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51c43a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               model  score_val eval_metric  pred_time_val  \\\n",
      "0                    CatBoost_BAG_L1   0.598026    accuracy       0.289819   \n",
      "1                WeightedEnsemble_L2   0.598026    accuracy       0.292404   \n",
      "2               CatBoost_r177_BAG_L1   0.597711    accuracy       0.378128   \n",
      "3                 CatBoost_r9_BAG_L1   0.591954    accuracy       0.219294   \n",
      "4                     XGBoost_BAG_L1   0.584720    accuracy       0.788037   \n",
      "5                  LightGBMXT_BAG_L1   0.583245    accuracy       0.813826   \n",
      "6                LightGBM_r96_BAG_L1   0.582277    accuracy       2.806550   \n",
      "7               LightGBM_r131_BAG_L1   0.580390    accuracy       1.115063   \n",
      "8                    LightGBM_BAG_L1   0.579229    accuracy       0.256374   \n",
      "9             NeuralNetFastAI_BAG_L1   0.576350    accuracy       0.351416   \n",
      "10       NeuralNetFastAI_r191_BAG_L1   0.575576    accuracy       0.654792   \n",
      "11              LightGBMLarge_BAG_L1   0.575358    accuracy       0.451282   \n",
      "12           RandomForestGini_BAG_L1   0.519329    accuracy       1.566191   \n",
      "13           RandomForestEntr_BAG_L1   0.517902    accuracy       1.292379   \n",
      "14             ExtraTreesGini_BAG_L1   0.514297    accuracy       1.092383   \n",
      "15             ExtraTreesEntr_BAG_L1   0.513281    accuracy       1.040090   \n",
      "16             KNeighborsUnif_BAG_L1   0.242960    accuracy       1.487708   \n",
      "17             KNeighborsDist_BAG_L1   0.240105    accuracy       1.422632   \n",
      "18        ExtraTreesEntr_BAG_L1_FULL        NaN    accuracy       1.040090   \n",
      "19        ExtraTreesGini_BAG_L1_FULL        NaN    accuracy       1.092383   \n",
      "20      RandomForestEntr_BAG_L1_FULL        NaN    accuracy       1.292379   \n",
      "21        KNeighborsDist_BAG_L1_FULL        NaN    accuracy       1.422632   \n",
      "22        KNeighborsUnif_BAG_L1_FULL        NaN    accuracy       1.487708   \n",
      "23      RandomForestGini_BAG_L1_FULL        NaN    accuracy       1.566191   \n",
      "24               XGBoost_BAG_L1_FULL        NaN    accuracy            NaN   \n",
      "25          WeightedEnsemble_L2_FULL        NaN    accuracy            NaN   \n",
      "26  NeuralNetFastAI_r191_BAG_L1_FULL        NaN    accuracy            NaN   \n",
      "27       NeuralNetFastAI_BAG_L1_FULL        NaN    accuracy            NaN   \n",
      "28          LightGBM_r96_BAG_L1_FULL        NaN    accuracy            NaN   \n",
      "29         LightGBM_r131_BAG_L1_FULL        NaN    accuracy            NaN   \n",
      "30              LightGBM_BAG_L1_FULL        NaN    accuracy            NaN   \n",
      "31            LightGBMXT_BAG_L1_FULL        NaN    accuracy            NaN   \n",
      "32         LightGBMLarge_BAG_L1_FULL        NaN    accuracy            NaN   \n",
      "33           CatBoost_r9_BAG_L1_FULL        NaN    accuracy            NaN   \n",
      "34         CatBoost_r177_BAG_L1_FULL        NaN    accuracy            NaN   \n",
      "35              CatBoost_BAG_L1_FULL        NaN    accuracy            NaN   \n",
      "\n",
      "      fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0   210.524133                0.289819         210.524133            1   \n",
      "1   211.824509                0.002585           1.300376            2   \n",
      "2    80.714466                0.378128          80.714466            1   \n",
      "3    82.625689                0.219294          82.625689            1   \n",
      "4     7.004151                0.788037           7.004151            1   \n",
      "5     3.352646                0.813826           3.352646            1   \n",
      "6     8.038526                2.806550           8.038526            1   \n",
      "7     5.601800                1.115063           5.601800            1   \n",
      "8     3.290556                0.256374           3.290556            1   \n",
      "9    26.066340                0.351416          26.066340            1   \n",
      "10   85.720152                0.654792          85.720152            1   \n",
      "11    3.625596                0.451282           3.625596            1   \n",
      "12    2.366735                1.566191           2.366735            1   \n",
      "13    2.912673                1.292379           2.912673            1   \n",
      "14    2.243743                1.092383           2.243743            1   \n",
      "15    1.625772                1.040090           1.625772            1   \n",
      "16    0.044698                1.487708           0.044698            1   \n",
      "17    0.042344                1.422632           0.042344            1   \n",
      "18    1.625772                1.040090           1.625772            1   \n",
      "19    2.243743                1.092383           2.243743            1   \n",
      "20    2.912673                1.292379           2.912673            1   \n",
      "21    0.042344                1.422632           0.042344            1   \n",
      "22    0.044698                1.487708           0.044698            1   \n",
      "23    2.366735                1.566191           2.366735            1   \n",
      "24    1.441143                     NaN           1.441143            1   \n",
      "25   20.820783                     NaN           1.300376            2   \n",
      "26   25.371332                     NaN          25.371332            1   \n",
      "27   10.949488                     NaN          10.949488            1   \n",
      "28    3.191316                     NaN           3.191316            1   \n",
      "29    1.609114                     NaN           1.609114            1   \n",
      "30    0.491213                     NaN           0.491213            1   \n",
      "31    0.977824                     NaN           0.977824            1   \n",
      "32    1.406192                     NaN           1.406192            1   \n",
      "33   10.549097                     NaN          10.549097            1   \n",
      "34    6.780283                     NaN           6.780283            1   \n",
      "35   19.520407                     NaN          19.520407            1   \n",
      "\n",
      "    can_infer  fit_order  \n",
      "0       False          8  \n",
      "1       False         18  \n",
      "2       False         13  \n",
      "3       False         16  \n",
      "4       False         11  \n",
      "5       False          4  \n",
      "6       False         17  \n",
      "7       False         14  \n",
      "8       False          5  \n",
      "9       False          3  \n",
      "10      False         15  \n",
      "11      False         12  \n",
      "12       True          6  \n",
      "13       True          7  \n",
      "14       True          9  \n",
      "15       True         10  \n",
      "16       True          1  \n",
      "17       True          2  \n",
      "18       True         28  \n",
      "19       True         27  \n",
      "20       True         25  \n",
      "21       True         20  \n",
      "22       True         19  \n",
      "23       True         24  \n",
      "24       True         29  \n",
      "25       True         36  \n",
      "26       True         33  \n",
      "27       True         21  \n",
      "28       True         35  \n",
      "29       True         32  \n",
      "30       True         23  \n",
      "31       True         22  \n",
      "32       True         30  \n",
      "33       True         34  \n",
      "34       True         31  \n",
      "35       True         26  \n"
     ]
    }
   ],
   "source": [
    "# 성능 확인\n",
    "leaderboard = predictor.leaderboard(silent=True)\n",
    "print(leaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11f54976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.555     0.554     0.554      2127\n",
      "           2      0.638     0.207     0.313      2008\n",
      "           3      0.557     0.615     0.584      2257\n",
      "           4      0.590     0.895     0.711      2427\n",
      "           5      0.719     0.660     0.688      1516\n",
      "\n",
      "    accuracy                          0.595     10335\n",
      "   macro avg      0.612     0.586     0.570     10335\n",
      "weighted avg      0.604     0.595     0.570     10335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "y_true = test_data[target_col]\n",
    "y_pred = predictor.predict(test_data)\n",
    "\n",
    "print(classification_report(y_true, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "018b8095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "위험도",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "a2efaf00-d633-4d1b-b3c4-6f58a94392f8",
       "rows": [
        [
         "0",
         "2"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 1
       }
      },
      "text/plain": [
       "0    2\n",
       "Name: 위험도, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측용 샘플 생성\n",
    "sample = pd.DataFrame([{\n",
    "    '시군구': '종로구',\n",
    "    '사고유형': '차대사람 - 차도통행중',\n",
    "    '도로형태': '교차로 - 교차로부근'\n",
    "}])\n",
    "\n",
    "# 누락된 feature 추가\n",
    "sample['시군구_평균사고'] = sample['시군구'].map(avg_by_area)\n",
    "sample['사고도로조합'] = sample['사고유형'] + '_' + sample['도로형태']\n",
    "\n",
    "# 예측\n",
    "pred = predictor.predict(sample)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c670f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>연도</th>\n",
       "      <th>시군구</th>\n",
       "      <th>법정동코드</th>\n",
       "      <th>사고내용</th>\n",
       "      <th>사망자수</th>\n",
       "      <th>중상자수</th>\n",
       "      <th>경상자수</th>\n",
       "      <th>부상신고자수</th>\n",
       "      <th>사고유형</th>\n",
       "      <th>도로형태</th>\n",
       "      <th>피해자 상해정도</th>\n",
       "      <th>피해가중점수</th>\n",
       "      <th>사고유형가중치</th>\n",
       "      <th>도로형태가중치</th>\n",
       "      <th>최종위험점수</th>\n",
       "      <th>위험도</th>\n",
       "      <th>시군구_평균사고</th>\n",
       "      <th>시군구_편차</th>\n",
       "      <th>사고도로조합</th>\n",
       "      <th>시군구_사고유형</th>\n",
       "      <th>시군구_도로형태</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2020</td>\n",
       "      <td>서울특별시 종로구 창성동</td>\n",
       "      <td>1111010500</td>\n",
       "      <td>중상사고</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>차대사람 - 차도통행중</td>\n",
       "      <td>교차로 - 교차로부근</td>\n",
       "      <td>중상</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.131882</td>\n",
       "      <td>0.111938</td>\n",
       "      <td>0.221910</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.015843</td>\n",
       "      <td>차대사람 - 차도통행중_교차로 - 교차로부근</td>\n",
       "      <td>서울특별시 종로구 창성동_차대사람 - 차도통행중</td>\n",
       "      <td>서울특별시 종로구 창성동_교차로 - 교차로부근</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020</td>\n",
       "      <td>서울특별시 종로구 창성동</td>\n",
       "      <td>1111010500</td>\n",
       "      <td>중상사고</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>차대사람 - 차도통행중</td>\n",
       "      <td>교차로 - 교차로안</td>\n",
       "      <td>중상</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.131882</td>\n",
       "      <td>0.117951</td>\n",
       "      <td>0.224917</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.015843</td>\n",
       "      <td>차대사람 - 차도통행중_교차로 - 교차로안</td>\n",
       "      <td>서울특별시 종로구 창성동_차대사람 - 차도통행중</td>\n",
       "      <td>서울특별시 종로구 창성동_교차로 - 교차로안</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020</td>\n",
       "      <td>서울특별시 종로구 통인동</td>\n",
       "      <td>1111010800</td>\n",
       "      <td>경상사고</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>차대사람 - 기타</td>\n",
       "      <td>단일로 - 기타</td>\n",
       "      <td>경상</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.092425</td>\n",
       "      <td>0.121204</td>\n",
       "      <td>0.116814</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.105843</td>\n",
       "      <td>차대사람 - 기타_단일로 - 기타</td>\n",
       "      <td>서울특별시 종로구 통인동_차대사람 - 기타</td>\n",
       "      <td>서울특별시 종로구 통인동_단일로 - 기타</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020</td>\n",
       "      <td>서울특별시 종로구 누상동</td>\n",
       "      <td>1111010900</td>\n",
       "      <td>경상사고</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>차대사람 - 차도통행중</td>\n",
       "      <td>교차로 - 교차로안</td>\n",
       "      <td>경상</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.131882</td>\n",
       "      <td>0.117951</td>\n",
       "      <td>0.134917</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.105843</td>\n",
       "      <td>차대사람 - 차도통행중_교차로 - 교차로안</td>\n",
       "      <td>서울특별시 종로구 누상동_차대사람 - 차도통행중</td>\n",
       "      <td>서울특별시 종로구 누상동_교차로 - 교차로안</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020</td>\n",
       "      <td>서울특별시 종로구 누상동</td>\n",
       "      <td>1111010900</td>\n",
       "      <td>경상사고</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>차대사람 - 기타</td>\n",
       "      <td>단일로 - 기타</td>\n",
       "      <td>경상</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.092425</td>\n",
       "      <td>0.121204</td>\n",
       "      <td>0.116814</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.105843</td>\n",
       "      <td>차대사람 - 기타_단일로 - 기타</td>\n",
       "      <td>서울특별시 종로구 누상동_차대사람 - 기타</td>\n",
       "      <td>서울특별시 종로구 누상동_단일로 - 기타</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv('../..//시도_시군구별_보행자_사고_사고유형_전처리ver.csv')\n",
    "\n",
    "# # 피해 가중 점수 계산\n",
    "# df['피해가중점수'] = (\n",
    "#     df['사망자수'] * 1 +\n",
    "#     df['중상자수'] * 0.1 +\n",
    "#     df['경상자수'] * 0.01 +\n",
    "#     df['부상신고자수'] * 0.001\n",
    "# )\n",
    "\n",
    "# # 사고유형 가중치\n",
    "# type_weight = df.groupby('사고유형')['피해가중점수'].mean()\n",
    "# df['사고유형가중치'] = df['사고유형'].map(type_weight)\n",
    "\n",
    "# # 도로형태 가중치\n",
    "# road_weight = df.groupby('도로형태')['피해가중점수'].mean()\n",
    "# df['도로형태가중치'] = df['도로형태'].map(road_weight)\n",
    "\n",
    "# # 최종 위험 점수\n",
    "# df['최종위험점수'] = df['피해가중점수'] + 0.5 * (df['사고유형가중치'] + df['도로형태가중치'])\n",
    "\n",
    "# # 위험도 등급 (1=안전, 5=위험)\n",
    "# df['위험도'] = pd.qcut(df['최종위험점수'], q=5, labels=[1, 2, 3, 4, 5]).astype(str)\n",
    "\n",
    "# # 시군구별 평균 피해가중점수\n",
    "# area_avg = df.groupby('시군구')['피해가중점수'].mean().to_dict()\n",
    "# df['시군구_평균사고'] = df['시군구'].map(area_avg)\n",
    "\n",
    "# # 전체 평균과의 편차\n",
    "# overall_avg = df['피해가중점수'].mean()\n",
    "# df['시군구_편차'] = df['시군구_평균사고'] - overall_avg\n",
    "\n",
    "# # 조합 변수 생성\n",
    "# df['사고도로조합'] = df['사고유형'] + '_' + df['도로형태']\n",
    "# df['시군구_사고유형'] = df['시군구'] + '_' + df['사고유형']\n",
    "# df['시군구_도로형태'] = df['시군구'] + '_' + df['도로형태']\n",
    "# HTML(df.head(5).to_html(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3990b71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.11.11\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.4.0: Fri Apr 11 18:33:39 PDT 2025; root:xnu-11417.101.15~117/RELEASE_ARM64_T6020\n",
      "CPU Count:          12\n",
      "Memory Avail:       2.66 GB / 16.00 GB (16.6%)\n",
      "Disk Space Avail:   6.31 GB / 460.43 GB (1.4%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "===================================================\n",
      "Presets specified: ['high_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 225s of the 900s of remaining time (25%).\n",
      "\t\tContext path: \"/Users/leehyunseung/Documents/GitHub/1_team_project/notebooks/03_modeling/MyModel_2/ds_sub_fit/sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                           model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0    NeuralNetFastAI_BAG_L2_FULL       0.581537   0.585717    accuracy        3.270630            NaN  48.946758                 0.053702                     NaN          12.811347            2       True         10\n",
      "1         LightGBMXT_BAG_L1_FULL       0.580666   0.584737    accuracy        0.027654            NaN   1.135443                 0.027654                     NaN           1.135443            1       True          4\n",
      "2       WeightedEnsemble_L2_FULL       0.580449   0.585200    accuracy        0.127542            NaN  16.192374                 0.001852                     NaN           0.479969            2       True          9\n",
      "3           LightGBM_BAG_L1_FULL       0.579795   0.579457    accuracy        0.016094            NaN   0.596526                 0.016094                     NaN           0.596526            1       True          5\n",
      "4           CatBoost_BAG_L1_FULL       0.578924   0.581390    accuracy        0.032693            NaN   2.840474                 0.032693                     NaN           2.840474            1       True          8\n",
      "5    NeuralNetFastAI_BAG_L1_FULL       0.564990   0.577334    accuracy        0.049249            NaN  11.139962                 0.049249                     NaN          11.139962            1       True          3\n",
      "6         LightGBMXT_BAG_L2_FULL       0.564555   0.644721    accuracy        3.397992            NaN  46.076943                 0.181064                     NaN           9.941532            2       True         11\n",
      "7       WeightedEnsemble_L3_FULL       0.564555   0.644721    accuracy        3.399305            NaN  46.709717                 0.001313                     NaN           0.632774            3       True         12\n",
      "8   RandomForestGini_BAG_L1_FULL       0.521881   0.522685    accuracy        0.667440       3.518639  10.200136                 0.667440                3.518639          10.200136            1       True          6\n",
      "9   RandomForestEntr_BAG_L1_FULL       0.521446   0.521650    accuracy        0.548326       3.348929   9.805260                 0.548326                3.348929           9.805260            1       True          7\n",
      "10    KNeighborsUnif_BAG_L1_FULL       0.486392   0.483793    accuracy        1.005545       5.457640   0.231449                 1.005545                5.457640           0.231449            1       True          1\n",
      "11    KNeighborsDist_BAG_L1_FULL       0.482909   0.486569    accuracy        0.869927       5.157056   0.186161                 0.869927                5.157056           0.186161            1       True          2\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t281s\t = DyStack   runtime |\t619s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 619s\n",
      "AutoGluon will save models to \"/Users/leehyunseung/Documents/GitHub/1_team_project/notebooks/03_modeling/MyModel_2\"\n",
      "Train Data Rows:    41336\n",
      "Train Data Columns: 8\n",
      "Label Column:       위험도\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 5\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3385.98 MB\n",
      "\tTrain Data (Original)  Memory Usage: 38.08 MB (1.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['시군구', '시군구_사고유형', '시군구_도로형태']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 869\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 869 to 866 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 2 | ['시군구_평균사고', '시군구_편차']\n",
      "\t\t('object', [])       : 3 | ['사고유형', '도로형태', '사고도로조합']\n",
      "\t\t('object', ['text']) : 3 | ['시군구', '시군구_사고유형', '시군구_도로형태']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   3 | ['사고유형', '도로형태', '사고도로조합']\n",
      "\t\t('category', ['text_as_category'])  :   3 | ['시군구', '시군구_사고유형', '시군구_도로형태']\n",
      "\t\t('float', [])                       :   2 | ['시군구_평균사고', '시군구_편차']\n",
      "\t\t('int', ['binned', 'text_special']) :  14 | ['시군구.char_count', '시군구.word_count', '시군구.digit_ratio', '시군구.symbol_ratio. ', '시군구_사고유형.char_count', ...]\n",
      "\t\t('int', ['text_ngram'])             : 621 | ['__nlp__.가평군', '__nlp__.강남구', '__nlp__.강동구', '__nlp__.강릉시', '__nlp__.강북구', ...]\n",
      "\t6.7s = Fit runtime\n",
      "\t8 features in original data used to generate 643 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 50.50 MB (1.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 6.85s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 612.12s of the 612.11s of remaining time.\n",
      "\t0.4873\t = Validation score   (accuracy)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t8.19s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 602.74s of the 602.74s of remaining time.\n",
      "\t0.4852\t = Validation score   (accuracy)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t8.23s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 593.96s of the 593.95s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 16.64% memory usage per fold, 66.56%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=16.64%)\n",
      "\t0.5768\t = Validation score   (accuracy)\n",
      "\t38.56s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 551.94s of the 551.93s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 15.60% memory usage per fold, 62.39%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=15.60%)\n",
      "\t0.583\t = Validation score   (accuracy)\n",
      "\t10.46s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 538.79s of the 538.79s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 14.81% memory usage per fold, 59.26%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=14.81%)\n",
      "\t0.5778\t = Validation score   (accuracy)\n",
      "\t10.1s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 526.62s of the 526.61s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 221 due to low memory. Expected memory usage reduced from 20.33% -> 15.0% of available memory...\n",
      "\t0.5232\t = Validation score   (accuracy)\n",
      "\t12.91s\t = Training   runtime\n",
      "\t4.2s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 508.75s of the 508.74s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 200 due to low memory. Expected memory usage reduced from 22.47% -> 15.0% of available memory...\n",
      "\t0.5231\t = Validation score   (accuracy)\n",
      "\t11.78s\t = Training   runtime\n",
      "\t3.87s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 492.03s of the 492.03s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 1 folds in parallel instead (Estimated 45.14% memory usage per fold, 45.14%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=10, gpus=0, memory=45.14%)\n",
      "\t\tSwitching to pseudo sequential ParallelFoldFittingStrategy to avoid Python memory leakage.\n",
      "\t\tOverrule this behavior by setting fold_fitting_strategy to 'sequential_local' in ag_args_ensemble when when calling `predictor.fit`\n",
      "\t0.5984\t = Validation score   (accuracy)\n",
      "\t254.07s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 235.01s of the 235.00s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 150 due to low memory. Expected memory usage reduced from 29.85% -> 15.0% of available memory...\n",
      "\t0.5159\t = Validation score   (accuracy)\n",
      "\t8.75s\t = Training   runtime\n",
      "\t3.26s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 222.01s of the 222.00s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 162 due to low memory. Expected memory usage reduced from 27.77% -> 15.0% of available memory...\n",
      "\t0.5149\t = Validation score   (accuracy)\n",
      "\t10.37s\t = Training   runtime\n",
      "\t3.35s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 207.11s of the 207.10s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 26.60% memory usage per fold, 53.21%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=5, gpus=0, memory=26.60%)\n",
      "\t0.5855\t = Validation score   (accuracy)\n",
      "\t25.28s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 178.87s of the 178.87s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.23% memory usage per fold, 40.94%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=10.23%)\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=4761, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2169, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/ray/_private/worker.py\", line 2782, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/ray/_private/worker.py\", line 929, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=4761, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 174.54s of the 174.53s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 35.02% memory usage per fold, 70.03%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=5, gpus=0, memory=35.02%)\n",
      "2025-06-05 14:34:11,785\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=4756, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "2025-06-05 14:34:11,792\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=4762, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "2025-06-05 14:34:11,792\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=4758, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "2025-06-05 14:34:11,793\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=4759, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "2025-06-05 14:34:11,794\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=4760, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\t0.5762\t = Validation score   (accuracy)\n",
      "\t59.45s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 113.30s of the 113.30s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 1 folds in parallel instead (Estimated 43.64% memory usage per fold, 43.64%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=10, gpus=0, memory=43.64%)\n",
      "\t\tSwitching to pseudo sequential ParallelFoldFittingStrategy to avoid Python memory leakage.\n",
      "\t\tOverrule this behavior by setting fold_fitting_strategy to 'sequential_local' in ag_args_ensemble when when calling `predictor.fit`\n",
      "\t0.5961\t = Validation score   (accuracy)\n",
      "\t104.02s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 6.85s of the 6.85s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.52% memory usage per fold, 46.07%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=2, gpus=0, memory=11.52%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r79_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=5120, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2169, in _train_and_save\n",
      "    model = self._train_single(**model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/trainer/abstract_trainer.py\", line 2055, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, total_resources=total_resources, **model_fit_kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 270, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 390, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 848, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 690, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 631, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 587, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 550, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size, fit_num_cpus, fit_num_gpus = self.ray.get(finished)\n",
      "                                                                                                                                     ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/ray/_private/worker.py\", line 2782, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/ray/_private/worker.py\", line 929, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=5120, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 2.15s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 1.0}\n",
      "\t0.5984\t = Validation score   (accuracy)\n",
      "\t1.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 617.91s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 18130.3 rows/s (5167 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.28s\t = Training   runtime\n",
      "\t8.19s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t0.27s\t = Training   runtime\n",
      "\t8.23s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "2025-06-05 14:37:04,078\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=5118, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "2025-06-05 14:37:04,080\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=5117, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "2025-06-05 14:37:04,081\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2025-06-05 14:37:04,082\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=5122, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "2025-06-05 14:37:04,083\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=5119, ip=127.0.0.1)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 413, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1051, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 209, in _fit\n",
      "    train_dataset = self._generate_dataset(X=X, y=y, train_params=processor_kwargs, is_train=True)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 687, in _generate_dataset\n",
      "    dataset = self._process_train_data(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 749, in _process_train_data\n",
      "    self.processor = create_preprocessor(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/ESTsoft_TP_1/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/utils/data_preprocessor.py\", line 40, in create_preprocessor\n",
      "    return ColumnTransformer(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: ColumnTransformer.__init__() got an unexpected keyword argument 'force_int_remainder_cols'\n",
      "\tStopping at the best epoch learned earlier - 15.\n",
      "\t10.19s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t1.79s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.88s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t12.91s\t = Training   runtime\n",
      "\t4.2s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t11.78s\t = Training   runtime\n",
      "\t3.87s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t23.63s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t8.75s\t = Training   runtime\n",
      "\t3.26s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t10.37s\t = Training   runtime\n",
      "\t3.35s\t = Validation runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t1.49s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t2.35s\t = Training   runtime\n",
      "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: CatBoost_r177_BAG_L1_FULL ...\n",
      "\t9.57s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 1.0}\n",
      "\t1.04s\t = Training   runtime\n",
      "Updated best model to \"CatBoost_BAG_L1_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"CatBoost_BAG_L1_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 62.65s ... Best model: \"CatBoost_BAG_L1_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/leehyunseung/Documents/GitHub/1_team_project/notebooks/03_modeling/MyModel_2\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5929366231253024,\n",
       " 'balanced_accuracy': 0.5834618133963303,\n",
       " 'mcc': 0.494717728607096}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Feature 목록\n",
    "# feature_cols = [\n",
    "#     '시군구', '사고유형', '도로형태',\n",
    "#     '시군구_평균사고', '시군구_편차',\n",
    "#     '사고도로조합', '시군구_사고유형', '시군구_도로형태'\n",
    "# ]\n",
    "# target_col = '위험도'\n",
    "\n",
    "# # 결측치 제거\n",
    "# df_model = df[feature_cols + [target_col]].dropna()\n",
    "\n",
    "# # 학습/테스트 분리\n",
    "# train_data, test_data = train_test_split(\n",
    "#     df_model, test_size=0.2, random_state=42, stratify=df_model[target_col]\n",
    "# )\n",
    "\n",
    "# # AutoGluon 학습\n",
    "# predictor = TabularPredictor(label=target_col, path='MyModel_2', problem_type='multiclass').fit(\n",
    "#     train_data=train_data,\n",
    "#     presets='high_quality',  # 성능 우선\n",
    "#     time_limit=900,          # 15분 제한\n",
    "#     num_cpus=10,\n",
    "#     verbosity=2\n",
    "# )\n",
    "\n",
    "# # 평가\n",
    "# predictor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d7411d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           model  score_val eval_metric  pred_time_val  \\\n",
      "0                CatBoost_BAG_L1   0.598389    accuracy       0.284616   \n",
      "1            WeightedEnsemble_L2   0.598389    accuracy       0.287621   \n",
      "2           CatBoost_r177_BAG_L1   0.596139    accuracy       0.239805   \n",
      "3                 XGBoost_BAG_L1   0.585519    accuracy       0.467451   \n",
      "4              LightGBMXT_BAG_L1   0.583027    accuracy       0.447050   \n",
      "5                LightGBM_BAG_L1   0.577753    accuracy       0.204574   \n",
      "6         NeuralNetFastAI_BAG_L1   0.576785    accuracy       0.340838   \n",
      "7           LightGBMLarge_BAG_L1   0.576229    accuracy       0.226127   \n",
      "8        RandomForestGini_BAG_L1   0.523176    accuracy       4.196429   \n",
      "9        RandomForestEntr_BAG_L1   0.523055    accuracy       3.873621   \n",
      "10         ExtraTreesGini_BAG_L1   0.515943    accuracy       3.264198   \n",
      "11         ExtraTreesEntr_BAG_L1   0.514926    accuracy       3.352923   \n",
      "12         KNeighborsUnif_BAG_L1   0.487251    accuracy       8.192992   \n",
      "13         KNeighborsDist_BAG_L1   0.485219    accuracy       8.228383   \n",
      "14    ExtraTreesGini_BAG_L1_FULL        NaN    accuracy       3.264198   \n",
      "15    ExtraTreesEntr_BAG_L1_FULL        NaN    accuracy       3.352923   \n",
      "16  RandomForestEntr_BAG_L1_FULL        NaN    accuracy       3.873621   \n",
      "17  RandomForestGini_BAG_L1_FULL        NaN    accuracy       4.196429   \n",
      "18    KNeighborsUnif_BAG_L1_FULL        NaN    accuracy       8.192992   \n",
      "19    KNeighborsDist_BAG_L1_FULL        NaN    accuracy       8.228383   \n",
      "20           XGBoost_BAG_L1_FULL        NaN    accuracy            NaN   \n",
      "21      WeightedEnsemble_L2_FULL        NaN    accuracy            NaN   \n",
      "22   NeuralNetFastAI_BAG_L1_FULL        NaN    accuracy            NaN   \n",
      "23          LightGBM_BAG_L1_FULL        NaN    accuracy            NaN   \n",
      "24        LightGBMXT_BAG_L1_FULL        NaN    accuracy            NaN   \n",
      "25     LightGBMLarge_BAG_L1_FULL        NaN    accuracy            NaN   \n",
      "26     CatBoost_r177_BAG_L1_FULL        NaN    accuracy            NaN   \n",
      "27          CatBoost_BAG_L1_FULL        NaN    accuracy            NaN   \n",
      "\n",
      "      fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
      "0   254.065232                0.284616         254.065232            1   \n",
      "1   255.100407                0.003005           1.035175            2   \n",
      "2   104.024173                0.239805         104.024173            1   \n",
      "3    25.275271                0.467451          25.275271            1   \n",
      "4    10.464253                0.447050          10.464253            1   \n",
      "5    10.098763                0.204574          10.098763            1   \n",
      "6    38.557274                0.340838          38.557274            1   \n",
      "7    59.452343                0.226127          59.452343            1   \n",
      "8    12.905424                4.196429          12.905424            1   \n",
      "9    11.776987                3.873621          11.776987            1   \n",
      "10    8.745685                3.264198           8.745685            1   \n",
      "11   10.366866                3.352923          10.366866            1   \n",
      "12    0.281250                8.192992           0.281250            1   \n",
      "13    0.266390                8.228383           0.266390            1   \n",
      "14    8.745685                3.264198           8.745685            1   \n",
      "15   10.366866                3.352923          10.366866            1   \n",
      "16   11.776987                3.873621          11.776987            1   \n",
      "17   12.905424                4.196429          12.905424            1   \n",
      "18    0.281250                8.192992           0.281250            1   \n",
      "19    0.266390                8.228383           0.266390            1   \n",
      "20    1.485896                     NaN           1.485896            1   \n",
      "21   24.662982                     NaN           1.035175            2   \n",
      "22   10.186864                     NaN          10.186864            1   \n",
      "23    0.875823                     NaN           0.875823            1   \n",
      "24    1.789201                     NaN           1.789201            1   \n",
      "25    2.345797                     NaN           2.345797            1   \n",
      "26    9.570397                     NaN           9.570397            1   \n",
      "27   23.627807                     NaN          23.627807            1   \n",
      "\n",
      "    can_infer  fit_order  \n",
      "0       False          8  \n",
      "1       False         14  \n",
      "2       False         13  \n",
      "3       False         11  \n",
      "4       False          4  \n",
      "5       False          5  \n",
      "6       False          3  \n",
      "7       False         12  \n",
      "8        True          6  \n",
      "9        True          7  \n",
      "10       True          9  \n",
      "11       True         10  \n",
      "12       True          1  \n",
      "13       True          2  \n",
      "14       True         23  \n",
      "15       True         24  \n",
      "16       True         21  \n",
      "17       True         20  \n",
      "18       True         15  \n",
      "19       True         16  \n",
      "20       True         25  \n",
      "21       True         28  \n",
      "22       True         17  \n",
      "23       True         19  \n",
      "24       True         18  \n",
      "25       True         26  \n",
      "26       True         27  \n",
      "27       True         22  \n"
     ]
    }
   ],
   "source": [
    "# leaderboard = predictor.leaderboard(silent=True)\n",
    "# print(leaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651d091a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1차 결과 (위험점수 기반)\n",
    "# 해석 가능성:       높음 (정량적 피해 반영)\n",
    "# 일반화 가능성:     높음 (새 지역에도 적용 가능)\n",
    "# 모델 복잡도:       낮음 (수치형 중심)\n",
    "# 성능:            소폭 우세\n",
    "\n",
    "# 2차 결과 (조합 기반)\n",
    "# 해석 가능성:       낮음 (복합조합 가중치 해석 어려움)\n",
    "# 일반화 가능성:      낮음 (훈련된 조합 정보 필요)\n",
    "# 모델 복잡도:       높음 (카테고리 피처 다수)\n",
    "# 성능:            근소 열세\n",
    "\n",
    "# =======================================================\n",
    "\n",
    "# 사용한 feature\n",
    "\n",
    "# 피해가중점수 (사망자수, 중상자수, 경상자수, 부상신고자수 반영)\n",
    "# 사고유형가중치\n",
    "# 도로형태가중치\n",
    "# =======================================================\n",
    "\n",
    "# 최종위험점수 = 피해가중점수 + 0.5 × (사고유형가중치 + 도로형태가중치)\n",
    "\n",
    "# =======================================================\n",
    "# 예측 성능 지표\n",
    "\n",
    "# Accuracy: 0.595\n",
    "# Balanced Accuracy: 0.586\n",
    "# MCC (Matthews Correlation Coefficient): 0.498\n",
    "\n",
    "# =======================================================\n",
    "\n",
    "# 모델 성능\n",
    "# Top model: CatBoost_BAG_L1 + WeightedEnsemble_L2\n",
    "# 최고 성능: Accuracy 0.598"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ESTsoft_TP_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
